{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4foVEKhrlqcH"
      },
      "source": [
        "#📌 Extracão"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1--uPM88l7JH"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import requests\n",
        "import json\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def extract_telecom_data_github():\n",
        "\n",
        "    print(\"Conectando à API da Telecom X...\")\n",
        "\n",
        "    try:\n",
        "        url = \"https://raw.githubusercontent.com/ingridcristh/challenge2-data-science/main/TelecomX_Data.json\"\n",
        "\n",
        "        headers = {\n",
        "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',\n",
        "            'Accept': 'application/json'\n",
        "        }\n",
        "\n",
        "        response = requests.get(url, headers=headers, timeout=30)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        data = response.json()\n",
        "\n",
        "        if isinstance(data, list):\n",
        "            df = pd.DataFrame(data)\n",
        "        else:\n",
        "            df = pd.DataFrame(data.get('customers', data))\n",
        "\n",
        "        print(f\"{len(df)} registros extraídos com sucesso!\")\n",
        "        return df\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Erro na requisição: {e}\")\n",
        "        return None\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"Erro ao decodificar JSON: {e}\")\n",
        "        return None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lSZP8zmmGZu"
      },
      "source": [
        "#🔧 Transformação"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def handle_missing_values(df):\n",
        "    df_clean = df.copy()\n",
        "\n",
        "    if 'gender' in df_clean.columns and df_clean['gender'].isnull().any():\n",
        "        mode_gender = df_clean['gender'].mode()[0]\n",
        "        df_clean['gender'] = df_clean['gender'].fillna(mode_gender)\n",
        "\n",
        "    if 'InternetService' in df_clean.columns and df_clean['InternetService'].isnull().any():\n",
        "        df_clean['InternetService'] = df_clean['InternetService'].fillna('No internet service')\n",
        "\n",
        "    if 'TotalCharges' in df_clean.columns:\n",
        "        df_clean['TotalCharges'] = pd.to_numeric(df_clean['TotalCharges'], errors='coerce')\n",
        "        mask_new_customers = (df_clean['TotalCharges'].isnull()) & (df_clean['tenure'] <= 1)\n",
        "        df_clean.loc[mask_new_customers, 'TotalCharges'] = df_clean.loc[mask_new_customers, 'MonthlyCharges']\n",
        "        remaining_nulls = df_clean['TotalCharges'].isnull()\n",
        "        if remaining_nulls.any():\n",
        "            df_clean['TotalCharges'] = df_clean['TotalCharges'].fillna(df_clean['TotalCharges'].median())\n",
        "\n",
        "    return df_clean\n",
        "\n",
        "def remove_duplicates(df):\n",
        "    df_dedup = df.copy()\n",
        "    initial_count = len(df_dedup)\n",
        "    df_dedup = df_dedup.drop_duplicates()\n",
        "\n",
        "    if 'customerID' in df_dedup.columns:\n",
        "        df_dedup = df_dedup.loc[df_dedup.groupby('customerID').apply(\n",
        "            lambda x: x.isnull().sum(axis=1).idxmin(), include_groups=False\n",
        "        )]\n",
        "\n",
        "    return df_dedup\n",
        "\n",
        "def fix_categorical_inconsistencies(df):\n",
        "    df_consistent = df.copy()\n",
        "    corrections = {\n",
        "        'gender': {'M': 'Male', 'F': 'Female', 'male': 'Male', 'female': 'Female'},\n",
        "        'Partner': {'Y': 'Yes', 'N': 'No', 'yes': 'Yes', 'no': 'No'},\n",
        "        'Dependents': {'Y': 'Yes', 'N': 'No', 'yes': 'Yes', 'no': 'No'},\n",
        "        'Churn': {'1': 'Yes', '0': 'No', 'TRUE': 'Yes', 'FALSE': 'No'}\n",
        "    }\n",
        "\n",
        "    for col, mapping in corrections.items():\n",
        "        if col in df_consistent.columns:\n",
        "            df_consistent[col] = df_consistent[col].replace(mapping)\n",
        "\n",
        "    return df_consistent\n",
        "\n",
        "def add_daily_charges(df):\n",
        "    df_new = df.copy()\n",
        "    if 'MonthlyCharges' in df_new.columns:\n",
        "        df_new['Contas_Diarias'] = df_new['MonthlyCharges'] / 30\n",
        "    return df_new\n",
        "\n",
        "def transform_binary_columns(df):\n",
        "    df_transformed = df.copy()\n",
        "    binary_map = {'Yes': 1, 'No': 0}\n",
        "\n",
        "    binary_columns = ['Partner', 'Dependents', 'PhoneService', 'PaperlessBilling', 'Churn']\n",
        "\n",
        "    for col in binary_columns:\n",
        "        if col in df_transformed.columns:\n",
        "            df_transformed[col] = df_transformed[col].map(binary_map)\n",
        "\n",
        "    return df_transformed\n",
        "\n",
        "def standardize_data_types(df):\n",
        "    df_typed = df.copy()\n",
        "\n",
        "    categorical_columns = ['gender', 'InternetService', 'Contract', 'PaymentMethod']\n",
        "    for col in categorical_columns:\n",
        "        if col in df_typed.columns:\n",
        "            df_typed[col] = df_typed[col].astype('category')\n",
        "\n",
        "    numeric_columns = {'MonthlyCharges': 'float64', 'TotalCharges': 'float64',\n",
        "                      'tenure': 'int64', 'SeniorCitizen': 'int64'}\n",
        "\n",
        "    for col, dtype in numeric_columns.items():\n",
        "        if col in df_typed.columns:\n",
        "            if col in ['MonthlyCharges', 'TotalCharges']:\n",
        "                df_typed[col] = pd.to_numeric(df_typed[col], errors='coerce')\n",
        "            df_typed[col] = df_typed[col].astype(dtype)\n",
        "\n",
        "    return df_typed\n"
      ],
      "metadata": {
        "id": "Yj-hlh_yHLzV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "bsm-WTLjmHvt"
      },
      "outputs": [],
      "source": [
        "def run_transformation_pipeline(df):\n",
        "    df_clean = handle_missing_values(df)\n",
        "    df_dedup = remove_duplicates(df_clean)\n",
        "    df_consistent = fix_categorical_inconsistencies(df_dedup)\n",
        "    df_daily = add_daily_charges(df_consistent)\n",
        "    df_binary = transform_binary_columns(df_daily)\n",
        "    df_final = standardize_data_types(df_binary)\n",
        "\n",
        "    return df_final"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XnTC2NTmMRL"
      },
      "source": [
        "#📊 Carga e análise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "1jgUnLqTmPdd"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def calculate_descriptive_statistics(df):\n",
        "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
        "    categorical_cols = df.select_dtypes(include=['object', 'category']).columns\n",
        "\n",
        "    stats_summary = {}\n",
        "    stats_summary['numeric'] = df[numeric_cols].describe()\n",
        "    stats_summary['categorical'] = df[categorical_cols].describe()\n",
        "\n",
        "    return stats_summary\n",
        "\n",
        "def analyze_churn_distribution(df):\n",
        "    if 'Churn' not in df.columns:\n",
        "        return None\n",
        "\n",
        "    churn_counts = df['Churn'].value_counts()\n",
        "    churn_percentages = df['Churn'].value_counts(normalize=True) * 100\n",
        "\n",
        "    distribution_summary = {\n",
        "        'counts': churn_counts,\n",
        "        'percentages': churn_percentages\n",
        "    }\n",
        "\n",
        "    return distribution_summary\n",
        "\n",
        "def analyze_categorical_vs_churn(df, categorical_columns):\n",
        "    if 'Churn' not in df.columns:\n",
        "        return None\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    for col in categorical_columns:\n",
        "        if col in df.columns:\n",
        "            crosstab = pd.crosstab(df[col], df['Churn'], normalize='index') * 100\n",
        "            results[col] = crosstab\n",
        "\n",
        "    return results\n",
        "\n",
        "def analyze_numerical_vs_churn(df, numerical_columns):\n",
        "    if 'Churn' not in df.columns:\n",
        "        return None\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    for col in numerical_columns:\n",
        "        if col in df.columns:\n",
        "            group_stats = df.groupby('Churn')[col].agg(['mean', 'median', 'std', 'count'])\n",
        "            results[col] = group_stats\n",
        "\n",
        "    return results\n",
        "\n",
        "def create_churn_visualizations(df):\n",
        "    visualizations_data = {}\n",
        "\n",
        "    if 'Churn' in df.columns:\n",
        "        churn_counts = df['Churn'].value_counts()\n",
        "        visualizations_data['churn_distribution'] = {\n",
        "            'labels': churn_counts.index.tolist(),\n",
        "            'values': churn_counts.values.tolist()\n",
        "        }\n",
        "\n",
        "    return visualizations_data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_correlation_matrix(df):\n",
        "    numeric_df = df.select_dtypes(include=[np.number])\n",
        "    correlation_matrix = numeric_df.corr()\n",
        "    return correlation_matrix\n",
        "\n",
        "def run_analysis_pipeline(df):\n",
        "    descriptive_stats = calculate_descriptive_statistics(df)\n",
        "    churn_distribution = analyze_churn_distribution(df)\n",
        "\n",
        "    categorical_cols = ['gender', 'Contract', 'PaymentMethod', 'InternetService']\n",
        "    categorical_analysis = analyze_categorical_vs_churn(df, categorical_cols)\n",
        "\n",
        "    numerical_cols = ['tenure', 'MonthlyCharges', 'TotalCharges', 'Contas_Diarias']\n",
        "    numerical_analysis = analyze_numerical_vs_churn(df, numerical_cols)\n",
        "\n",
        "    correlations = generate_correlation_matrix(df)\n",
        "    visualizations = create_churn_visualizations(df)\n",
        "\n",
        "    analysis_results = {\n",
        "        'descriptive_statistics': descriptive_stats,\n",
        "        'churn_distribution': churn_distribution,\n",
        "        'categorical_analysis': categorical_analysis,\n",
        "        'numerical_analysis': numerical_analysis,\n",
        "        'correlations': correlations,\n",
        "        'visualizations': visualizations\n",
        "    }\n",
        "\n",
        "    return analysis_results\n"
      ],
      "metadata": {
        "id": "XVbluPbJLvcm"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-WzfSvTmaw9"
      },
      "source": [
        "#📄Relatorio Final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "XMTac0YJmeK9"
      },
      "outputs": [],
      "source": [
        "def generate_introduction():\n",
        "    introduction = {\n",
        "        'objective': 'Analisar o comportamento de churn dos clientes da Telecom X',\n",
        "        'problem': 'Alto índice de cancelamentos impacta a receita e crescimento da empresa',\n",
        "        'goal': 'Identificar padrões e fatores que levam à evasão para desenvolver estratégias de retenção'\n",
        "    }\n",
        "    return introduction\n",
        "\n",
        "def summarize_data_cleaning(original_records, final_records, issues_fixed):\n",
        "    cleaning_summary = {\n",
        "        'original_records': original_records,\n",
        "        'final_records': final_records,\n",
        "        'retention_rate': (final_records / original_records) * 100,\n",
        "        'issues_addressed': issues_fixed\n",
        "    }\n",
        "    return cleaning_summary\n",
        "\n",
        "def extract_key_insights(analysis_results):\n",
        "    insights = []\n",
        "\n",
        "    if 'churn_distribution' in analysis_results:\n",
        "        churn_rate = analysis_results['churn_distribution']['percentages'].get(1, 0)\n",
        "        insights.append(f\"Taxa geral de churn: {churn_rate:.1f}%\")\n",
        "\n",
        "    if 'categorical_analysis' in analysis_results:\n",
        "        contract_analysis = analysis_results['categorical_analysis'].get('Contract', None)\n",
        "        if contract_analysis is not None:\n",
        "            monthly_churn = contract_analysis.loc['Month-to-month', 1] if 'Month-to-month' in contract_analysis.index else 0\n",
        "            insights.append(f\"Contratos mensais apresentam maior risco de churn: {monthly_churn:.1f}%\")\n",
        "\n",
        "    if 'numerical_analysis' in analysis_results:\n",
        "        tenure_analysis = analysis_results['numerical_analysis'].get('tenure', None)\n",
        "        if tenure_analysis is not None:\n",
        "            avg_tenure_churned = tenure_analysis.loc[1, 'mean']\n",
        "            avg_tenure_retained = tenure_analysis.loc[0, 'mean']\n",
        "            insights.append(f\"Clientes que cancelaram têm tenure médio de {avg_tenure_churned:.1f} meses vs {avg_tenure_retained:.1f} meses dos que permaneceram\")\n",
        "\n",
        "    return insights\n",
        "\n",
        "def generate_recommendations():\n",
        "    recommendations = [\n",
        "        'Implementar programa de fidelização para contratos de longo prazo',\n",
        "        'Melhorar processo de onboarding para novos clientes',\n",
        "        'Incentivar métodos de pagamento automáticos com descontos',\n",
        "        'Criar campanhas direcionadas para clientes de alto risco',\n",
        "        'Desenvolver sistema de alertas para identificação precoce de churn',\n",
        "        'Oferecer benefícios escalonados baseados no tempo de permanência'\n",
        "    ]\n",
        "    return recommendations\n",
        "\n",
        "def create_final_report(df_original, df_final, analysis_results):\n",
        "    report = {}\n",
        "\n",
        "    report['introducao'] = generate_introduction()\n",
        "\n",
        "    report['limpeza_dados'] = summarize_data_cleaning(\n",
        "        len(df_original),\n",
        "        len(df_final),\n",
        "        ['Valores ausentes tratados', 'Duplicatas removidas', 'Tipos padronizados', 'Inconsistências corrigidas']\n",
        "    )\n",
        "\n",
        "    report['analise_exploratoria'] = {\n",
        "        'metodo': 'Análise descritiva, distribuição de churn, análise categórica e numérica',\n",
        "        'ferramentas': 'Python, Pandas, visualizações estatísticas',\n",
        "        'variaveis_analisadas': ['gender', 'tenure', 'Contract', 'MonthlyCharges', 'TotalCharges', 'PaymentMethod']\n",
        "    }\n",
        "\n",
        "    report['insights'] = extract_key_insights(analysis_results)\n",
        "\n",
        "    report['conclusoes'] = [\n",
        "        'Contratos mensais representam maior risco de churn',\n",
        "        'Clientes novos são mais propensos ao cancelamento',\n",
        "        'Método de pagamento influencia na retenção',\n",
        "        'Tempo de permanência é inversamente correlacionado ao churn'\n",
        "    ]\n",
        "\n",
        "    report['recomendacoes'] = generate_recommendations()\n",
        "\n",
        "    return report"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def print_formatted_report(report):\n",
        "    print(\"RELATÓRIO DE ANÁLISE DE CHURN - TELECOM X\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    print(\"\\n1. INTRODUÇÃO\")\n",
        "    print(\"-\"*20)\n",
        "    intro = report['introducao']\n",
        "    print(f\"Objetivo: {intro['objective']}\")\n",
        "    print(f\"Problema: {intro['problem']}\")\n",
        "    print(f\"Meta: {intro['goal']}\")\n",
        "\n",
        "    print(\"\\n2. LIMPEZA E TRATAMENTO DE DADOS\")\n",
        "    print(\"-\"*35)\n",
        "    cleaning = report['limpeza_dados']\n",
        "    print(f\"Registros originais: {cleaning['original_records']}\")\n",
        "    print(f\"Registros finais: {cleaning['final_records']}\")\n",
        "    print(f\"Taxa de retenção: {cleaning['retention_rate']:.1f}%\")\n",
        "    print(\"Correções aplicadas:\")\n",
        "    for issue in cleaning['issues_addressed']:\n",
        "        print(f\"  - {issue}\")\n",
        "\n",
        "    print(\"\\n3. ANÁLISE EXPLORATÓRIA DE DADOS\")\n",
        "    print(\"-\"*32)\n",
        "    eda = report['analise_exploratoria']\n",
        "    print(f\"Método: {eda['metodo']}\")\n",
        "    print(f\"Ferramentas: {eda['ferramentas']}\")\n",
        "    print(f\"Variáveis analisadas: {', '.join(eda['variaveis_analisadas'])}\")\n",
        "\n",
        "    print(\"\\n4. PRINCIPAIS INSIGHTS\")\n",
        "    print(\"-\"*22)\n",
        "    for insight in report['insights']:\n",
        "        print(f\"  - {insight}\")\n",
        "\n",
        "    print(\"\\n5. CONCLUSÕES\")\n",
        "    print(\"-\"*14)\n",
        "    for conclusion in report['conclusoes']:\n",
        "        print(f\"  - {conclusion}\")\n",
        "\n",
        "    print(\"\\n6. RECOMENDAÇÕES\")\n",
        "    print(\"-\"*17)\n",
        "    for recommendation in report['recomendacoes']:\n",
        "        print(f\"  - {recommendation}\")\n",
        "\n",
        "def run_final_report_pipeline(df_original, df_final, analysis_results):\n",
        "    final_report = create_final_report(df_original, df_final, analysis_results)\n",
        "    print_formatted_report(final_report)\n",
        "    return final_report\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "M-cAKVVRL6Uq"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dqdAnjilMiLL"
      },
      "execution_count": 11,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}